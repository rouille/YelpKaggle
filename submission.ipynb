{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Building business-photos correspondence\n",
    "We build a a hash table to easily access the photos of a given business. This information is enclosed in the `test_photo_to_biz.csv` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photo</th>\n",
       "      <th>business</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>317818</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30679</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>455084</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>371381</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86224</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36076</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>46999</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>74896</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>169399</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>110581</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    photo business\n",
       "0  317818    003sg\n",
       "1   30679    003sg\n",
       "2  455084    003sg\n",
       "3  371381    003sg\n",
       "4   86224    003sg\n",
       "5   36076    003sg\n",
       "6   46999    003sg\n",
       "7   74896    003sg\n",
       "8  169399    003sg\n",
       "9  110581    003sg"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from common import *\n",
    "\n",
    "\n",
    "# Photo id to business id for the test dataset\n",
    "photo2biz = pd.read_csv('data/test_photo_to_biz.csv', header = 0, names = ['photo','business'])\n",
    "\n",
    "# First rows\n",
    "photo2biz.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business\n",
       "003sg    [317818, 30679, 455084, 371381, 86224, 36076, ...\n",
       "00er5    [220529, 239591, 398090, 315725, 444173, 35412...\n",
       "00kad    [96324, 333815, 101340, 398801, 465446, 123159...\n",
       "00mc6    [219849, 327514, 189070, 366342, 227137, 15566...\n",
       "00q7x    [207951, 44259, 25772, 256585, 375771, 284229,...\n",
       "00v0t    [98656, 289068, 356683, 356072, 384160, 257167...\n",
       "00y7p    [354534, 91842, 264321, 337598, 425924, 318190...\n",
       "019fg    [329682, 293765, 151022, 310278, 214887, 41965...\n",
       "019r1    [235703, 330900, 97541, 334820, 318846, 70608,...\n",
       "01i5j    [159653, 186559, 210259, 104371, 230924, 39826...\n",
       "Name: photo, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biz2photos = photo2biz.groupby('business')['photo'].apply(list)\n",
    "\n",
    "biz2photos.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10000 businesses in the test dataset.\n"
     ]
    }
   ],
   "source": [
    "biz2photos = biz2photos.to_dict()\n",
    "biz = list(biz2photos.keys())\n",
    "\n",
    "print('There are %d businesses in the test dataset.' % len(biz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model\n",
    "The architecture of the neural network (NN) is defined below. The bottleneck features, as returned by the ResNet-50 deep learning model, will be fed to this NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 9)                 2313      \n",
      "=================================================================\n",
      "Total params: 2,763,785\n",
      "Trainable params: 2,760,201\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.layers import Conv2D, Dense, Dropout, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GlobalAveragePooling2D(input_shape=(1, 1, 2048)))\n",
    "\n",
    "model.add(Dense(1024, activation='relu', kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(512, activation='relu', kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(9, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weight of the NN are downloaded. Note that the model has been trained in this [notebook](nn.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('data/saved_models/weights_resnet50.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predictions\n",
    "For each business, we calculate the ResNet-50 bottleneck features and make predictions using the above NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def id2files(ids):\n",
    "    basename = 'data/test_photos/'\n",
    "    files = [basename + str(id) + '.jpg' for id in ids]\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/10000\n",
      "500/10000\n",
      "1000/10000\n",
      "1500/10000\n",
      "2000/10000\n",
      "2500/10000\n",
      "3000/10000\n",
      "3500/10000\n",
      "4000/10000\n",
      "4500/10000\n",
      "5000/10000\n",
      "5500/10000\n",
      "6000/10000\n",
      "6500/10000\n",
      "7000/10000\n",
      "7500/10000\n",
      "8000/10000\n",
      "8500/10000\n",
      "9000/10000\n",
      "9500/10000\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "resnet50 = ResNet50(include_top=False)\n",
    "\n",
    "yhat = []\n",
    "\n",
    "for i, b in enumerate(biz):\n",
    "    if i % 500 == 0: print(\"%d/%d\" % (i, len(biz)) )\n",
    "    photos = biz2photos[b]\n",
    "    files = id2files(photos)\n",
    "    tensors = preprocess_input(paths_to_tensor_nobar(files))\n",
    "    features = resnet50.predict(tensors)\n",
    "    predictions = model.predict(features)\n",
    "    yhat.append(np.mean(predictions, axis=0))\n",
    "\n",
    "yhat = np.array(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probabilities as returned by the NN are converted to labels (0 or 1) using a unique threshold of 0.5 for all class as well as custom thresholds for each class. The custom thresholds have been derived in this [notebook](findBestThreshold.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yhat_unique = (yhat >= 0.5).astype(int)\n",
    "\n",
    "threshold = np.array([0.43, 0.55, 0.535, 0.525, 0.545, 0.54, 0.55, 0.47, 0.5])\n",
    "yhat_custom = np.array([[1 if yhat[i,j] >= threshold[j] else 0 for j in range(9)] \n",
    "                        for i in range(len(yhat))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Write Files\n",
    "Files for submission are exported in csv format. We also save the predictions before thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def write_files(labels, fname, biz=biz):\n",
    "    with open(fname, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['business_id','labels'])\n",
    "        for i, l in zip(biz, labels):\n",
    "            writer.writerow([i,' '.join(map(str, np.where(l==1)[0]))])\n",
    "\n",
    "write_files(yhat_unique, 'unique.csv')\n",
    "write_files(yhat_custom, 'custom.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez('yhat.npz', business=biz, predictions=yhat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
