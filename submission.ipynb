{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Building business-photos correspondence\n",
    "We build a a hash table to easily access the photos of a given business. This information is enclosed in the `test_photo_to_biz.csv` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photo</th>\n",
       "      <th>business</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>317818</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30679</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>455084</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>371381</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86224</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36076</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>46999</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>74896</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>169399</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>110581</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    photo business\n",
       "0  317818    003sg\n",
       "1   30679    003sg\n",
       "2  455084    003sg\n",
       "3  371381    003sg\n",
       "4   86224    003sg\n",
       "5   36076    003sg\n",
       "6   46999    003sg\n",
       "7   74896    003sg\n",
       "8  169399    003sg\n",
       "9  110581    003sg"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from common import *\n",
    "\n",
    "\n",
    "# Photo id to business id for the test dataset\n",
    "photo2biz = pd.read_csv('data/test_photo_to_biz.csv', header = 0, names = ['photo','business'])\n",
    "\n",
    "# First rows\n",
    "photo2biz.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business\n",
       "003sg    [317818, 30679, 455084, 371381, 86224, 36076, ...\n",
       "00er5    [220529, 239591, 398090, 315725, 444173, 35412...\n",
       "00kad    [96324, 333815, 101340, 398801, 465446, 123159...\n",
       "00mc6    [219849, 327514, 189070, 366342, 227137, 15566...\n",
       "00q7x    [207951, 44259, 25772, 256585, 375771, 284229,...\n",
       "00v0t    [98656, 289068, 356683, 356072, 384160, 257167...\n",
       "00y7p    [354534, 91842, 264321, 337598, 425924, 318190...\n",
       "019fg    [329682, 293765, 151022, 310278, 214887, 41965...\n",
       "019r1    [235703, 330900, 97541, 334820, 318846, 70608,...\n",
       "01i5j    [159653, 186559, 210259, 104371, 230924, 39826...\n",
       "Name: photo, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biz2photos = photo2biz.groupby('business')['photo'].apply(list)\n",
    "\n",
    "biz2photos.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10000 businesses in the test dataset.\n"
     ]
    }
   ],
   "source": [
    "biz2photos = biz2photos.to_dict()\n",
    "biz = list(biz2photos.keys())\n",
    "\n",
    "print('There are %d businesses in the test dataset.' % len(biz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model\n",
    "The architecture of the neural network (NN) is defined below. The bottleneck features, as returned by the ResNet-50 deep learning model will be fed to this NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 9)                 2313      \n",
      "=================================================================\n",
      "Total params: 2,763,785\n",
      "Trainable params: 2,760,201\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.layers import Conv2D, Dense, Dropout, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GlobalAveragePooling2D(input_shape=(1, 1, 2048)))\n",
    "\n",
    "model.add(Dense(1024, activation='relu', kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(512, activation='relu', kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(9, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weight of the NN are downloaded. Note that the model has been trained in this [notebook](nn.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('data/saved_models/weights_resnet50.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def id2files(ids):\n",
    "    basename = 'data/test_photos/'\n",
    "    files = [basename + str(id) + '.jpg' for id in ids]\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/10000\n",
      "500/10000\n",
      "1000/10000\n",
      "1500/10000\n",
      "2000/10000\n",
      "2500/10000\n",
      "3000/10000\n",
      "3500/10000\n",
      "4000/10000\n",
      "4500/10000\n",
      "5000/10000\n",
      "5500/10000\n",
      "6000/10000\n",
      "6500/10000\n",
      "7000/10000\n",
      "7500/10000\n",
      "8000/10000\n",
      "8500/10000\n",
      "9000/10000\n",
      "9500/10000\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "resnet50 = ResNet50(include_top=False)\n",
    "\n",
    "yhat = []\n",
    "\n",
    "for i, b in enumerate(biz):\n",
    "    if i % 500 == 0: print(\"%d/%d\" % (i, len(biz)) )\n",
    "    photos = biz2photos[b]\n",
    "    files = id2files(photos)\n",
    "    tensors = preprocess_input(paths_to_tensor_nobar(files))\n",
    "    features = resnet50.predict(tensors)\n",
    "    predictions = model.predict(features)\n",
    "    yhat.append(np.mean(predictions, axis=0))\n",
    "\n",
    "yhat = np.array(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yhat_unique = (yhat >= 0.5).astype(int)\n",
    "\n",
    "threshold = np.array([0.43, 0.55, 0.535, 0.525, 0.545, 0.54, 0.55, 0.47, 0.5])\n",
    "yhat_custom = np.array([[1 if yhat[i,j] >= threshold[j] else 0 for j in range(9)] \n",
    "                        for i in range(len(yhat))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Write Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def write_files(labels, fname, biz=biz):\n",
    "    with open(fname, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['business_id','labels'])\n",
    "        for i, l in zip(biz, labels):\n",
    "            writer.writerow([i,' '.join(map(str, np.where(l==1)[0]))])\n",
    "\n",
    "write_files(yhat_unique, 'unique.csv')\n",
    "write_files(yhat_custom, 'custom.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez('yhat.npz', business=biz, predictions=yhat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
