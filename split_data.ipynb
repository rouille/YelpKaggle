{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing for Yelp Restaurant Photo Classification competition\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Import Libraries and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 234842 training images\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from common import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Business id to labels\n",
    "biz2labels = pd.read_csv('data/train.csv', header = 0, names = ['business','labels']).fillna('')\n",
    "\n",
    "# Photo id to business id for the training dataset\n",
    "photo2biz_train = pd.read_csv('data/train_photo_to_biz_ids.csv', header = 0, names = ['photo','business'])\n",
    "\n",
    "# Get list of images\n",
    "all_files, all_ids = path_to_images('data/train_photos')\n",
    "\n",
    "print('There are %d training images' % len(all_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract Labels for Each Photo in Training Dataset\n",
    "The `biz2labels` data frame is slightly rearranged in order to efficiently access the labels associated to each business. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>(1, 2, 3, 4, 5, 6, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>(0, 1, 6, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>(1, 2, 4, 5, 6, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>(1, 2, 4, 5, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>(0, 6, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>(1, 2, 3, 4, 5, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>(2, 3, 5, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>(1, 2, 3, 5, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>(1, 2, 4, 5, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>(1, 5, 6, 7)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         labels\n",
       "business                       \n",
       "1000      (1, 2, 3, 4, 5, 6, 7)\n",
       "1001               (0, 1, 6, 8)\n",
       "100          (1, 2, 4, 5, 6, 7)\n",
       "1006            (1, 2, 4, 5, 6)\n",
       "1010                  (0, 6, 8)\n",
       "101          (1, 2, 3, 4, 5, 6)\n",
       "1011               (2, 3, 5, 6)\n",
       "1012            (1, 2, 3, 5, 6)\n",
       "1014            (1, 2, 4, 5, 6)\n",
       "1015               (1, 5, 6, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biz2labels['labels'] = biz2labels['labels'].apply(lambda x: tuple(sorted(int(t) for t in x.split())))\n",
    "biz2labels.set_index('business', inplace=True)\n",
    "biz2labels.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are nine different labels:\n",
    "* 0 = good_for_lunch\n",
    "* 1 = good_for_dinner\n",
    "* 2 = takes_reservations\n",
    "* 3 = outdoor_seating\n",
    "* 4 = restaurant_is_expensive\n",
    "* 5 = has_alcohol\n",
    "* 6 = has_table_service\n",
    "* 7 = ambience_is_classy\n",
    "* 8 = good_for_kids\n",
    "\n",
    "The labels are then encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 234842 - Number of columns: 9\n"
     ]
    }
   ],
   "source": [
    "all_targets = np.vstack(biz2labels.loc[photo2biz_train['business']]['labels'].apply(encode_label))\n",
    "print('Number of rows: %d - Number of columns: %d' % (all_targets.shape[0], all_targets.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split Training Dataset into Training, Validation and Test Datasets\n",
    "The original training dataset is splitted into a training, validation and test datasets. The validation and test datasets are allocated 12.5% of the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 176131 images in the training dataset\n",
      "There are 29355 images in the validation dataset\n",
      "There are 29356 images in the test dataset\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_files, test_files, train_targets, test_targets = train_test_split(all_files,\n",
    "                                                                        all_targets,\n",
    "                                                                        test_size=0.25,\n",
    "                                                                        random_state=7)\n",
    "\n",
    "valid_files, valid_targets = (test_files[:int(len(test_files)/2)], test_targets[:int(len(test_files)/2)])\n",
    "test_files, test_targets = (test_files[int(len(test_files)/2):], test_targets[int(len(test_files)/2):])\n",
    "\n",
    "print('There are %d images in the training dataset' % len(train_files))\n",
    "print('There are %d images in the validation dataset' % len(valid_files))\n",
    "print('There are %d images in the test dataset' % len(test_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save Arrays\n",
    "The path to the images and the correponding labels are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez('data/preprocess/train.npz', img=train_files, target=train_targets)\n",
    "np.savez('data/preprocess/valid.npz', img=valid_files, target=valid_targets)\n",
    "np.savez('data/preprocess/test.npz', img=test_files, target=test_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
